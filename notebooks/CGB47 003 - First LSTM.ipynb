{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bff22d22",
   "metadata": {},
   "source": [
    "# First LSTM Model\n",
    "Author: Camilla Billari <br> \n",
    "Date: 19/01/24\n",
    "\n",
    "Fitting my first LSTM to the Marone p4581 experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d680b4a8-f747-4ebc-9459-1c5f2d1ea356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import local modules\n",
    "from utils.dataset import SlowEarthquakeDataset\n",
    " \n",
    "# Change local path\n",
    "MAIN_DICT = \"/gws/nopw/j04/ai4er/users/pn341/earthquake-predictability\"\n",
    "sys.path.append(MAIN_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0110f9ed",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f3a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories paths\n",
    "GTC_DATA_DIR = \"/gws/nopw/j04/ai4er/users/pn341/earthquake-predictability/data/gtc_quakes_data\"\n",
    "LABQUAKES_DATA_DIR = f\"{GTC_DATA_DIR}/labquakes\"\n",
    "DATA_DIR = f\"{LABQUAKES_DATA_DIR}/Marone\"\n",
    "EXP = \"p4581\"\n",
    "\n",
    "# Open experiment in a dataframe\n",
    "EXP_FILE_PATH = f\"{DATA_DIR}/{EXP}/{EXP}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a9f388-7c2f-4869-9e78-035c8daed0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access experiment and output dataframe head using Pritt's data loaders (which utilises Adriano's loading + pre-processing)\n",
    "dataset = SlowEarthquakeDataset([EXP])\n",
    "dataset.load()\n",
    "\n",
    "# Get data optupts\n",
    "ds_exp = dataset[EXP]\n",
    "X, Y, t = ds_exp[\"X\"], ds_exp[\"Y\"], ds_exp[\"t\"]\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(\n",
    "    np.hstack((X, Y, t.reshape(-1, 1))),\n",
    "    columns=[ds_exp[\"hdrs\"][\"X\"], *ds_exp[\"hdrs\"][\"Y\"], ds_exp[\"hdrs\"][\"t\"]],\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885dac8a",
   "metadata": {},
   "source": [
    "### Creating the dataste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c475fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split for time series\n",
    "timeseries = df[\"det_shear_stress\"]\n",
    "\n",
    "train_size = int(len(timeseries) * 0.80)\n",
    "test_size = len(timeseries) - train_size\n",
    "train, test = timeseries[:train_size], timeseries[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a81440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, lookback):\n",
    "    \"\"\"Transform a time series into a prediction dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset: A numpy array of time series, first dimension is the time steps\n",
    "        lookback: Size of window for prediction\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset)-lookback):\n",
    "        feature = dataset[i:i+lookback]\n",
    "        target = dataset[i+1:i+lookback+1]\n",
    "        X.append(feature)\n",
    "        y.append(target)\n",
    "    return torch.tensor(X), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a560bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 4\n",
    "X_train, y_train = create_dataset(train, lookback=lookback)\n",
    "X_test, y_test = create_dataset(test, lookback=lookback)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352e4dda",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d140c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class AirModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.linear = nn.Linear(50, 1)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653281ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, _ = self.lstm(x)\n",
    "# # extract only the last time step\n",
    "# x = x[:, -1, :]\n",
    "# x = self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05ffd81",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e266699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    " \n",
    "model = AirModel()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=8)\n",
    " \n",
    "n_epochs = 2000\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Validation\n",
    "    if epoch % 100 != 0:\n",
    "        continue\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_train)\n",
    "        train_rmse = np.sqrt(loss_fn(y_pred, y_train))\n",
    "        y_pred = model(X_test)\n",
    "        test_rmse = np.sqrt(loss_fn(y_pred, y_test))\n",
    "    print(\"Epoch %d: train RMSE %.4f, test RMSE %.4f\" % (epoch, train_rmse, test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531eb72b",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45962885",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # shift train predictions for plotting\n",
    "    train_plot = np.ones_like(timeseries) * np.nan\n",
    "    y_pred = model(X_train)\n",
    "    y_pred = y_pred[:, -1, :]\n",
    "    train_plot[lookback:train_size] = model(X_train)[:, -1, :]\n",
    "    # shift test predictions for plotting\n",
    "    test_plot = np.ones_like(timeseries) * np.nan\n",
    "    test_plot[train_size+lookback:len(timeseries)] = model(X_test)[:, -1, :]\n",
    "# plot\n",
    "plt.plot(timeseries, c='b')\n",
    "plt.plot(train_plot, c='r')\n",
    "plt.plot(test_plot, c='g')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
