{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d680b4a8-f747-4ebc-9459-1c5f2d1ea356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "MAIN_DICT = \"/gws/nopw/j04/ai4er/users/pn341/earthquake-predictability\"\n",
    "sys.path.append(MAIN_DICT)\n",
    "\n",
    "from utils.dataset import SlowEarthquakeDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab923818",
   "metadata": {},
   "source": [
    "## Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "599f2b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last time value: 29316.2860000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lp_disp</th>\n",
       "      <th>LT</th>\n",
       "      <th>Tau</th>\n",
       "      <th>SigN</th>\n",
       "      <th>dcdtOB</th>\n",
       "      <th>slip</th>\n",
       "      <th>Time</th>\n",
       "      <th>Rec.1</th>\n",
       "      <th>timedcdt</th>\n",
       "      <th>ec_disp</th>\n",
       "      <th>mu</th>\n",
       "      <th>Shear_Strain</th>\n",
       "      <th>Slip</th>\n",
       "      <th>velocity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>3.1636940114</td>\n",
       "      <td>-0.0000000000</td>\n",
       "      <td>0.0000001000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>-0.1000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>-0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>3.1636930114</td>\n",
       "      <td>-0.0000000000</td>\n",
       "      <td>0.0000001000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>0.9000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>-0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>3.1636935114</td>\n",
       "      <td>-0.0000000000</td>\n",
       "      <td>0.0000001000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>2.0000000000</td>\n",
       "      <td>2.0000000000</td>\n",
       "      <td>1.9000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>-0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>3.1636940114</td>\n",
       "      <td>-0.0000000000</td>\n",
       "      <td>0.0000001000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>3.0000000000</td>\n",
       "      <td>3.0000000000</td>\n",
       "      <td>2.9000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>-0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>3.1636955114</td>\n",
       "      <td>-0.0000000000</td>\n",
       "      <td>0.0000001000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>4.0000000000</td>\n",
       "      <td>4.0000000000</td>\n",
       "      <td>3.9000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>-0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lp_disp            LT            Tau          SigN        dcdtOB  \\\n",
       "#                                                                          \n",
       "0  0.0000000000  3.1636940114  -0.0000000000  0.0000001000  0.0000000000   \n",
       "1  0.0000000000  3.1636930114  -0.0000000000  0.0000001000  0.0000000000   \n",
       "2  0.0000000000  3.1636935114  -0.0000000000  0.0000001000  0.0000000000   \n",
       "3  0.0000000000  3.1636940114  -0.0000000000  0.0000001000  0.0000000000   \n",
       "4  0.0000000000  3.1636955114  -0.0000000000  0.0000001000  0.0000000000   \n",
       "\n",
       "           slip          Time          Rec.1      timedcdt        ec_disp  \\\n",
       "#                                                                           \n",
       "0  0.0000000000  0.0000000000  -0.1000000000  0.0000000000  -0.0000000000   \n",
       "1  1.0000000000  1.0000000000   0.9000000000  0.0000000000  -0.0000000000   \n",
       "2  2.0000000000  2.0000000000   1.9000000000  0.0000000000  -0.0000000000   \n",
       "3  3.0000000000  3.0000000000   2.9000000000  0.0000000000  -0.0000000000   \n",
       "4  4.0000000000  4.0000000000   3.9000000000  0.0000000000  -0.0000000000   \n",
       "\n",
       "             mu  Shear_Strain Slip  velocity  \n",
       "#                                             \n",
       "0  0.0000000000  0.0000000000  NaN       NaN  \n",
       "1  0.0000000000  0.0000000000  NaN       NaN  \n",
       "2  0.0000000000  0.0000000000  NaN       NaN  \n",
       "3  0.0000000000  0.0000000000  NaN       NaN  \n",
       "4  0.0000000000  0.0000000000  NaN       NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directories paths\n",
    "GTC_DATA_DIR = \"/gws/nopw/j04/ai4er/users/pn341/earthquake-predictability/data/gtc_quakes_data\"\n",
    "LABQUAKES_DATA_DIR = f\"{GTC_DATA_DIR}/labquakes\"\n",
    "MELEVEEDU_DATA_DIR = f\"{LABQUAKES_DATA_DIR}/MeleVeeduetal2020\"\n",
    "\n",
    "# Open b698 experiment in a dataframe\n",
    "i417_FILE_PATH = f\"{MELEVEEDU_DATA_DIR}/b698/b698.txt\"\n",
    "with open(i417_FILE_PATH, \"r\") as file:\n",
    "    df = pd.read_csv(\n",
    "        file, delim_whitespace=True, header=0, index_col=0, low_memory=False\n",
    "    )\n",
    "\n",
    "# Remove units\n",
    "df = df.iloc[1:, :]\n",
    "\n",
    "# Handle exception for space in \"# Rec\" column name creating two separate columns\n",
    "cols = list(df.keys()) + [\"\"]  # create a new cols list\n",
    "df.columns = cols[1:]  # remove the first\n",
    "df.pop(df.columns[-1])  # pop the last column\n",
    "\n",
    "# Get the last index\n",
    "last_index = df.index[-1]\n",
    "\n",
    "# Get the value of the 'Time' column at the last index\n",
    "last_time = df.loc[last_index, \"Time\"]\n",
    "print(f\"Last time: {last_time}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0110f9ed",
   "metadata": {},
   "source": [
    "## Pre-processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97a9f388-7c2f-4869-9e78-035c8daed0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>det_shear_stress</th>\n",
       "      <th>obs_shear_stress</th>\n",
       "      <th>obs_normal_stress</th>\n",
       "      <th>obs_ecdisp</th>\n",
       "      <th>obs_shear_strain</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.105776</td>\n",
       "      <td>11.225116</td>\n",
       "      <td>17.382861</td>\n",
       "      <td>20.088637</td>\n",
       "      <td>22.167371</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.103531</td>\n",
       "      <td>11.222870</td>\n",
       "      <td>17.375571</td>\n",
       "      <td>20.088683</td>\n",
       "      <td>22.167447</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.105632</td>\n",
       "      <td>11.224972</td>\n",
       "      <td>17.385328</td>\n",
       "      <td>20.088975</td>\n",
       "      <td>22.167941</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.101784</td>\n",
       "      <td>11.221124</td>\n",
       "      <td>17.373017</td>\n",
       "      <td>20.088549</td>\n",
       "      <td>22.167221</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.106120</td>\n",
       "      <td>11.225461</td>\n",
       "      <td>17.386512</td>\n",
       "      <td>20.089116</td>\n",
       "      <td>22.168180</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   det_shear_stress  obs_shear_stress  obs_normal_stress  obs_ecdisp  \\\n",
       "0          0.105776         11.225116          17.382861   20.088637   \n",
       "1          0.103531         11.222870          17.375571   20.088683   \n",
       "2          0.105632         11.224972          17.385328   20.088975   \n",
       "3          0.101784         11.221124          17.373017   20.088549   \n",
       "4          0.106120         11.225461          17.386512   20.089116   \n",
       "\n",
       "   obs_shear_strain  time  \n",
       "0         22.167371  0.00  \n",
       "1         22.167447  0.01  \n",
       "2         22.167941  0.02  \n",
       "3         22.167221  0.03  \n",
       "4         22.168180  0.04  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access b698 and output dataframe head using Pritt's data loaders (which utilises Adriano's loading + pre-processing)\n",
    "dataset = SlowEarthquakeDataset([\"b698\"])\n",
    "dataset.load()\n",
    "\n",
    "# Get data optupts\n",
    "ds_exp = dataset[\"b698\"]\n",
    "X, Y, t = ds_exp[\"X\"], ds_exp[\"Y\"], ds_exp[\"t\"]\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(\n",
    "    np.hstack((X, Y, t.reshape(-1, 1))),\n",
    "    columns=[ds_exp[\"hdrs\"][\"X\"], *ds_exp[\"hdrs\"][\"Y\"], ds_exp[\"hdrs\"][\"t\"]],\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352e4dda",
   "metadata": {},
   "source": [
    "## Notes on Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d45de35",
   "metadata": {},
   "source": [
    "### General notes:\n",
    "\n",
    "* We have sampled 3.78% of dataset (in the 3650-3850 window).\n",
    "* Downsampling frequency = (from Mele Veedu).\n",
    "* Original columns were: [RecNum, lp_disp, LT, Tau, SigN, dcdtOB, Time, recN, timedcdt, ec_disp, mu, etrain, slipVelocity].\n",
    "* Pre-processed columns: [det6_shear_stress, obs_shear_stress, obs_normal_stress, obs_ecdisp, obs_shear_strain, time], where:\n",
    "    * Tau + polyfit -> det_shear_stress &emsp; (processed - detrended)\n",
    "    * Tau -> obs_shear_stress &emsp; &emsp; &emsp; &emsp; (not processed)\n",
    "    * SigN -> obs_normal_stress &emsp; &emsp; &emsp; (not processed)\n",
    "    * ec_disp -> obs_ecdisp &emsp; &emsp; &emsp; &emsp; &emsp;(processed - handles exceptions)\n",
    "    * etrain -> obs_shear_strain &emsp; &emsp;&emsp;&emsp;(processed - handles exceptions)\n",
    "    * Time -> time &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp;&emsp;&emsp;(not processed)\n",
    "* Pre-processing steps:\n",
    "    * Handling exceptions for ec_disp and etrain is done by discarding the data and creating empty columns for obs_ecdisp and obs_shear_strain. (See load_data(), lines 41-47.)\n",
    "    * De-trending for det_shear_stress is done by fitting np.polyfit to obs_shear_stress (degree=1), and then subtracting it from obs_shear_stress. (See load_data(), lines 62-63.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79d18dd",
   "metadata": {},
   "source": [
    "### Annotated Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c61e2",
   "metadata": {},
   "source": [
    "#### Setting Experiment Parameter\n",
    "From _params.py_: \n",
    "\n",
    "```python\n",
    "elif exp == \"i417\":\n",
    "        parameters = {\n",
    "            \"t0\": 3650.0,           # Starting time window loaded - Note: raw data min = 0\n",
    "            \"tend\": 3850.0,         # Ending time window loaded - Note: raw data max = 5285.9\n",
    "            \"Nheaders\": 2,          # Header that np array starts with in import_data\n",
    "            \"dir_data\": \"gtc_quakes_data/labquakes/\",\n",
    "            \"case_study\": \"MeleVeeduetal2020/i417\",\n",
    "            \"data_type\": \"lab\",\n",
    "            \"struct_type\": \"MeleVeeduetal2020\",\n",
    "            \"file_format\": \"txt\",\n",
    "            \"downsample_factor\": 1, # No downsampling (in != 1, no code has been written for it)\n",
    "            \"vl\": 10,               # Loading velocity\n",
    "            \"segment\": None,        # Only relevant for gnss data to segment the data\n",
    "            \"obs_unit\": \"MPa\",\n",
    "            \"time_unit\": \"s\",\n",
    "        }\n",
    "\n",
    "        [...] # Assigns new params for obs and time labels with units\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13213630",
   "metadata": {},
   "source": [
    "#### Importing Data\n",
    "Relevant parts from _load.py_: \n",
    "\n",
    "```python\n",
    "def import_data(dirs, filename, parameters):\n",
    "    [...] # sets format\n",
    "\n",
    "    if struct == \"MeleVeeduetal2020\":\n",
    "        [...] # accesses file\n",
    "\n",
    "            Nheaders = parameters[\"Nheaders\"] # From parameters, for \"i417\" =2\n",
    "            L = L - Nheaders\n",
    "\n",
    "            [...] # Creates new array columns, one per quantity in data (see below for assignment)\n",
    "\n",
    "            [...] # loads data, for loop to assign columns from data\n",
    "\n",
    "                # For each header, assign quantity from column - see comments for data column headers\n",
    "                Rec[tt] = int(columns[0])               # RecNum\n",
    "                LPDisp[tt] = float(columns[1])          # lp_disp (mic)\n",
    "                LayerThick[tt] = float(columns[2])      # LT (mic) - micrometer?\n",
    "                ShearStress[tt] = float(columns[3])     # Tau (MPa)\n",
    "                NormStress[tt] = float(columns[4])      # SigN (MPa)\n",
    "                OnBoard[tt] = float(columns[5])         # dcdtOB (mic) - micrometer?\n",
    "                Time[tt] = float(columns[6])            # Time (sec)\n",
    "                Rec_float[tt] = float(columns[7])       # recN\n",
    "                TimeOnBoard[tt] = float(columns[8])     # timedcdt (sec)\n",
    "                ecDisp[tt] = float(columns[9])          # ec_disp\n",
    "                mu[tt] = float(columns[10])             # mu\n",
    "                ShearStrain[tt] = float(columns[11])    # etrain\n",
    "                slip_velocity[tt] = float(columns[12])  # slipVelocity (micrometer/sec)\n",
    "\n",
    "            [...] # only keep indices with time between time range chosen (3650-3850) as set in parameters\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1026af63",
   "metadata": {},
   "source": [
    "#### Loading and Pre-processing\n",
    "Note: load_data() runs the import_data() which is the one with the loading code, the rest of the code in load_data() then processes it and outputs it into X, Y, t, dt, vl.\n",
    "\n",
    "Relevant parts from _load.py_: \n",
    "\n",
    "```python\n",
    "def load_data(exp, dirs, params):\n",
    "\n",
    "    if params[\"data_type\"] == \"lab\":\n",
    "            [...] # choose data based on params set and run import_data()\n",
    "\n",
    "            #---- Copy obs_shear_stress, obs_normal_stress as is!\n",
    "            ShearStressobs = data[\"ShearStress\"]\n",
    "            NormalStressobs = data[\"NormStress\"]\n",
    "\n",
    "            #---- Copy obs_ecdisp and obs_shear_strain, if error create an empty (NaN) column\n",
    "            try:\n",
    "                ecDispobs = data[\"ecDisp\"]\n",
    "            except Exception:\n",
    "                ecDispobs = np.nan * np.ones(ShearStressobs.shape)\n",
    "            try:\n",
    "                ShearStrainobs = data[\"ShearStrain\"]\n",
    "            except Exception:\n",
    "                ShearStrainobs = np.nan * np.ones(ShearStressobs.shape)\n",
    "\n",
    "            [...] # about n of samples, only relevant for Marone\n",
    "\n",
    "            #----  Reassign time for new range\n",
    "            if params[\"struct_type\"] == \"MeleVeeduetal2020\":\n",
    "                t = data[\"Time\"] - data[\"Time\"][0]\n",
    "                \n",
    "            [...] # handle time for other experiments\n",
    "\n",
    "            #---- Detrend shear stress (into our det_shear_stress) and normal stress\n",
    "            p = np.polyfit(t, ShearStressobs, deg=1)\n",
    "            ShearStressobs_det = ShearStressobs - (p[0] * t + p[1]) # our det_shear_stress\n",
    "            del p\n",
    "\n",
    "            [...] #---- Detrend normal stress, displacement and strain in same way,\n",
    "            #           but they are already commented out? No need?\n",
    "\n",
    "            #---- Assign outputs \n",
    "            # observed data\n",
    "            X = np.array([ShearStressobs_det]).T # our det_shear_stress, note it will be 1st column\n",
    "\n",
    "            # observed time step\n",
    "            dt = t[1] - t[0]\n",
    "\n",
    "            vl = params[\"vl\"]\n",
    "            [...] #---- Estimate loading velocity from loading displacenment if not present, but in i417 vl=10\n",
    "\n",
    "            # Y = np.array([ShearStressobs_det, NormalStressobs_det]).T\n",
    "            Y = np.array(\n",
    "                [ShearStressobs, NormalStressobs, ecDispobs, ShearStrainobs]\n",
    "            ).T\n",
    "            # our [obs_shear_stress, obs_normal_stress, obs_ecdisp, obs_shear_strain]\n",
    "            \n",
    "    \n",
    "    return X, Y, t, dt, vl # note we read the first 3 in as out 6 column dataset [X, Y, t]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
