{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b415eb84-c125-4a38-9781-e16f492d0f84",
   "metadata": {},
   "source": [
    "# Data Preprocessing Notes for p4679\n",
    "Author: Pritthijit Nath <br> \n",
    "Date: 17/01/24 <br>\n",
    "Notebook Template Credit: Camilla Billari\n",
    "\n",
    "Notes for the data preprocessing that was carried out upon loading the Chris Marone Lab Experiment p4679."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e131e80-e6d8-45cd-bd46-5a19e1ed6e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "MAIN_DICT = \"/gws/nopw/j04/ai4er/users/pn341/earthquake-predictability\"\n",
    "sys.path.append(MAIN_DICT)\n",
    "\n",
    "from utils.dataset import SlowEarthquakeDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a43a2e-4a99-46c0-971b-d3ac167d8d77",
   "metadata": {},
   "source": [
    "## Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "484518d7-00a2-484a-ab91-c9fe5214b6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lp_disp</th>\n",
       "      <th>shr_stress</th>\n",
       "      <th>nor_disp</th>\n",
       "      <th>nor_stress</th>\n",
       "      <th>time</th>\n",
       "      <th>mu</th>\n",
       "      <th>layer_thick</th>\n",
       "      <th>ec_disp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3893.90946</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3766.95473</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3893.90946</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3766.95473</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3893.90946</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3766.95473</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3893.90946</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3766.95473</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3893.90946</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3766.95473</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lp_disp  shr_stress    nor_disp    nor_stress  time   mu  layer_thick  \\\n",
       "0      0.0         0.0 -3893.90946  1.000000e-18   1.0  0.0   3766.95473   \n",
       "1      0.0         0.0 -3893.90946  1.000000e-18   2.0  0.0   3766.95473   \n",
       "2      0.0         0.0 -3893.90946  1.000000e-18   3.0  0.0   3766.95473   \n",
       "3      0.0         0.0 -3893.90946  1.000000e-18   4.0  0.0   3766.95473   \n",
       "4      0.0         0.0 -3893.90946  1.000000e-18   5.0  0.0   3766.95473   \n",
       "\n",
       "   ec_disp  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directories paths\n",
    "GTC_DATA_DIR = \"/gws/nopw/j04/ai4er/users/pn341/earthquake-predictability/data/gtc_quakes_data\"\n",
    "LABQUAKES_DATA_DIR = f\"{GTC_DATA_DIR}/labquakes\"\n",
    "MARONE_DATA_DIR = f\"{LABQUAKES_DATA_DIR}/Marone\"\n",
    "\n",
    "# Open p4679 experiment in a dataframe\n",
    "p4679_FILE_PATH = f\"{MARONE_DATA_DIR}/p4679/p4679.txt\"\n",
    "with open(p4679_FILE_PATH, \"r\") as file:\n",
    "    raw_df = pd.read_csv(file, skiprows=1)\n",
    "\n",
    "# Rename the columns to match the raw data\n",
    "raw_df.columns = [\n",
    "    \"id\",\n",
    "    \"lp_disp\",\n",
    "    \"shr_stress\",\n",
    "    \"nor_disp\",\n",
    "    \"nor_stress\",\n",
    "    \"time\",\n",
    "    \"mu\",\n",
    "    \"layer_thick\",\n",
    "    \"ec_disp\",\n",
    "]\n",
    "\n",
    "# Drop the record number column\n",
    "raw_df = raw_df.drop([\"id\"], axis=1)\n",
    "\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d873c5a6-3611-416e-9a53-0ff969894e42",
   "metadata": {},
   "source": [
    "## Pre-processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e750a7d1-57cb-4c30-983f-373b5c11517f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>det_shear_stress</th>\n",
       "      <th>obs_shear_stress</th>\n",
       "      <th>obs_normal_stress</th>\n",
       "      <th>obs_ecdisp</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.057305</td>\n",
       "      <td>5.091520</td>\n",
       "      <td>6.986740</td>\n",
       "      <td>22107.1104</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.056437</td>\n",
       "      <td>5.090652</td>\n",
       "      <td>6.988410</td>\n",
       "      <td>22109.7823</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.055774</td>\n",
       "      <td>5.089989</td>\n",
       "      <td>6.986299</td>\n",
       "      <td>22103.7900</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055277</td>\n",
       "      <td>5.089492</td>\n",
       "      <td>6.985970</td>\n",
       "      <td>22109.2161</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.054028</td>\n",
       "      <td>5.088243</td>\n",
       "      <td>6.987547</td>\n",
       "      <td>22108.5900</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   det_shear_stress  obs_shear_stress  obs_normal_stress  obs_ecdisp   time\n",
       "0          0.057305          5.091520           6.986740  22107.1104  0.000\n",
       "1          0.056437          5.090652           6.988410  22109.7823  0.001\n",
       "2          0.055774          5.089989           6.986299  22103.7900  0.002\n",
       "3          0.055277          5.089492           6.985970  22109.2161  0.003\n",
       "4          0.054028          5.088243           6.987547  22108.5900  0.004"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access p4679 and output dataframe head using Pritt's data loaders (which utilises Adriano's loading + pre-processing)\n",
    "dataset = SlowEarthquakeDataset([\"p4679\"])\n",
    "\n",
    "# Get data outputs\n",
    "ds_exp = dataset[\"p4679\"]\n",
    "X, Y, t = ds_exp[\"X\"], ds_exp[\"Y\"], ds_exp[\"t\"]\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(\n",
    "    np.hstack((X, Y, t.reshape(-1, 1))),\n",
    "    columns=[ds_exp[\"hdrs\"][\"X\"], *ds_exp[\"hdrs\"][\"Y\"], ds_exp[\"hdrs\"][\"t\"]],\n",
    ")\n",
    "\n",
    "# Dropping obs_shear_strain due to being filled with NaN\n",
    "df = df.drop([\"obs_shear_strain\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9d331da-d4eb-4d95-a2bc-95ec86de5deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = {}\n",
    "\n",
    "# Percentage of processed data\n",
    "analysis[\"%_processed\"] = round((len(df) / len(raw_df)) * 100, 2)\n",
    "\n",
    "# Raw time range\n",
    "analysis[\n",
    "    \"raw_time_range\"\n",
    "] = f\"{raw_df['time'].iloc[0]}-{raw_df['time'].iloc[-1]}\"\n",
    "\n",
    "# Sampled time range\n",
    "analysis[\"sampled_time_range\"] = f\"4233.28-4535\"\n",
    "\n",
    "# Raw dataset - column count\n",
    "analysis[\"raw_col_count\"] = len(raw_df.columns)\n",
    "\n",
    "# Processed dataset - column count\n",
    "analysis[\"proc_col_count\"] = len(df.columns)\n",
    "\n",
    "# Raw dataset - columns\n",
    "analysis[\"raw_cols\"] = list(raw_df.columns)\n",
    "\n",
    "# Processed dataset - columns\n",
    "analysis[\"proc_cols\"] = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "009e8f84-438e-4961-a1da-fd5baf9cb604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+---------------------------------------------------------------------------------------------+\n",
      "|    |                    |                                                                                             |\n",
      "|----+--------------------+---------------------------------------------------------------------------------------------|\n",
      "|  0 | %_processed        | 4.73                                                                                        |\n",
      "|  1 | raw_time_range     | 1.0-8382.329                                                                                |\n",
      "|  2 | sampled_time_range | 4233.28-4535                                                                                |\n",
      "|  3 | raw_col_count      | 8                                                                                           |\n",
      "|  4 | proc_col_count     | 5                                                                                           |\n",
      "|  5 | raw_cols           | ['lp_disp', 'shr_stress', 'nor_disp', 'nor_stress', 'time', 'mu', 'layer_thick', 'ec_disp'] |\n",
      "|  6 | proc_cols          | ['det_shear_stress', 'obs_shear_stress', 'obs_normal_stress', 'obs_ecdisp', 'time']         |\n",
      "+----+--------------------+---------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "x = pd.DataFrame([(k, analysis[k]) for k in analysis], columns=[\"\", \"\"])\n",
    "print(tabulate(x, headers=\"keys\", tablefmt=\"psql\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0d09fc-4ead-4b99-8e2b-ef2548692ed2",
   "metadata": {},
   "source": [
    "## Notes on Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65a5201-b967-4a47-91dc-299cf538d1e8",
   "metadata": {},
   "source": [
    "### General notes:\n",
    "\n",
    "* We have sampled 4.73% of dataset (in the 4233.28-4535 window).\n",
    "* Downsampling frequency = 1s (window), 0.1s (shift) (from Laurentti et al.).\n",
    "* Original columns were: [lp_disp, shr_stress, nor_disp, nor_stress, time, mu, layer_thick, ec_disp].\n",
    "* Pre-processed columns: [det_shear_stress, obs_shear_stress, obs_normal_stress, obs_ecdisp, time], where:\n",
    "    * shr_stress + polyfit -> det_shear_stress &emsp; (processed - detrended)\n",
    "    * shr_stress -> obs_shear_stress &emsp; &emsp; &emsp; &emsp; &nbsp; (not processed)\n",
    "    * nor_stress -> obs_normal_stress &emsp; &emsp; &emsp; (not processed)\n",
    "    * ec_disp -> obs_ecdisp &emsp; &emsp; &emsp; &emsp; &emsp;&emsp; &emsp;(processed - handles exceptions)\n",
    "    * Time -> time &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp;&emsp;&emsp; &emsp; &emsp;(not processed)\n",
    "* Pre-processing steps:\n",
    "    * Handling exceptions for ec_disp and obs_shear_strain is done by discarding the data and creating empty columns for obs_ecdisp and obs_shear_strain. (See load_data(), lines 42-49.)\n",
    "    * De-trending for det_shear_stress is done by fitting np.polyfit to obs_shear_stress (degree=1), and then subtracting it from obs_shear_stress. (See load_data(), lines 67-69.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f1740d-242b-40a6-bdb6-db412b99029a",
   "metadata": {},
   "source": [
    "### Annotated Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc5af6e-a558-43bb-aa2b-f97db131ad0d",
   "metadata": {},
   "source": [
    "#### Setting Experiment Parameter\n",
    "From _params.py_: \n",
    "\n",
    "```python\n",
    "elif exp == \"p4679\":\n",
    "        parameters = {\n",
    "            \"t0\": 4233.28,            # Starting time window loaded - Note: raw data min = 0\n",
    "            \"tend\": 4535.0,           # Ending time window loaded - Note: raw data max = 8382.329\n",
    "            \"Nheaders\": 2,            # Header that np array starts with in import_data\n",
    "            \"dir_data\": \"gtc_quakes_data/labquakes/\",\n",
    "            \"case_study\": \"Marone/p4679\",\n",
    "            \"data_type\": \"lab\",\n",
    "            \"struct_type\": \"Marone\",\n",
    "            \"file_format\": \"txt\",\n",
    "            \"downsample_factor\": 1,   # No downsampling (in != 1, no code has been written for it)\n",
    "            \"vl\": None,               # Loading velocity\n",
    "            \"segment\": None,          # Only relevant for gnss data to segment the data\n",
    "            \"obs_unit\": \"MPa\",\n",
    "            \"time_unit\": \"s\",\n",
    "        }\n",
    "        [...] # Assigns new params for obs and time labels with units\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b770c2-89a7-4a8e-b0bc-b1d724e74f04",
   "metadata": {},
   "source": [
    "#### Importing Data\n",
    "Relevant parts from _load.py_: \n",
    "\n",
    "```python\n",
    "def import_data(dirs, filename, parameters):\n",
    "    [...] # sets format\n",
    "\n",
    "    if struct == \"Marone\":\n",
    "        [...] # accesses file\n",
    "\n",
    "            Nheaders = parameters[\"Nheaders\"] # From parameters, for \"p4679\" =2\n",
    "            L = L - Nheaders\n",
    "\n",
    "            [...] # Creates new array columns, one per quantity in data (see below for assignment)\n",
    "\n",
    "            [...] # loads data, for loop to assign columns from data\n",
    "\n",
    "                # For each header, assign quantity from column - see comments for data column headers\n",
    "                Rec[tt] = int(columns[0])               # id\n",
    "                LPDisp[tt] = float(columns[1])          # lp_disp (mic)                \n",
    "                ShearStress[tt] = float(columns[2])     # shr_stress (MPa)\n",
    "                NormDisp[tt] = float(columns[3][:-1])   # nor_disp (mic)\n",
    "                NormStress[tt] = float(columns[4])      # nor_stress (MPa)\n",
    "                Time[tt] = float(columns[5])            # time (sec)                \n",
    "                mu[tt] = float(columns[6][:-1])         # mu\n",
    "                LayerThick[tt] = float(columns[7][:-1]) # layer_thick (mic)\n",
    "                ecDisp[tt] = float(columns[8])          # ec_disp (mic)\n",
    "\n",
    "            [...] # only keep indices with time between time range chosen (4233.28-4535) as set in parameters\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35418e8-d45e-467b-a1a8-c71309cc9b92",
   "metadata": {},
   "source": [
    "#### Loading and Pre-processing\n",
    "Note: load_data() runs the import_data() which is the one with the loading code, the rest of the code in load_data() then processes it and outputs it into X, Y, t, dt, vl.\n",
    "\n",
    "Relevant parts from _load.py_: \n",
    "\n",
    "```python\n",
    "def load_data(exp, dirs, params):\n",
    "\n",
    "    if params[\"data_type\"] == \"lab\":\n",
    "            [...] # choose data based on params set and run import_data()\n",
    "\n",
    "            #---- Copy obs_shear_stress, obs_normal_stress as is!\n",
    "            ShearStressobs = data[\"ShearStress\"]\n",
    "            NormalStressobs = data[\"NormStress\"]\n",
    "\n",
    "            #---- Copy obs_ecdisp and obs_shear_strain, if error create an empty (NaN) column\n",
    "            try:\n",
    "                ecDispobs = data[\"ecDisp\"]\n",
    "            except Exception:\n",
    "                ecDispobs = np.nan * np.ones(ShearStressobs.shape)\n",
    "            try:\n",
    "                ShearStrainobs = data[\"ShearStrain\"]\n",
    "            except Exception:\n",
    "                ShearStrainobs = np.nan * np.ones(ShearStressobs.shape)\n",
    "\n",
    "            [...] # about n of samples, only relevant for Marone\n",
    "\n",
    "            #----  Reassign time for new range\n",
    "            elif params[\"struct_type\"] == \"Marone\":\n",
    "                t = data[\"Time\"] - data[\"Time\"][0]\n",
    "                \n",
    "            [...] # handle time for other experiments\n",
    "\n",
    "            #---- Detrend shear stress (into our det_shear_stress) and normal stress\n",
    "            p = np.polyfit(t, ShearStressobs, deg=1)\n",
    "            ShearStressobs_det = ShearStressobs - (p[0] * t + p[1]) # our det_shear_stress\n",
    "            del p\n",
    "\n",
    "            [...] #---- Detrend normal stress, displacement and strain in same way,\n",
    "            #           but they are already commented out? No need?\n",
    "\n",
    "            #---- Assign outputs \n",
    "            # observed data\n",
    "            X = np.array([ShearStressobs_det]).T # our det_shear_stress, note it will be 1st column\n",
    "\n",
    "            # observed time step\n",
    "            dt = t[1] - t[0]\n",
    "\n",
    "            vl = params[\"vl\"]\n",
    "            [...] #---- Estimate loading velocity from loading displacenment if not present, but in p4679 vl=None\n",
    "\n",
    "            # Y = np.array([ShearStressobs_det, NormalStressobs_det]).T\n",
    "            Y = np.array(\n",
    "                [ShearStressobs, NormalStressobs, ecDispobs, ShearStrainobs]\n",
    "            ).T\n",
    "            # our [obs_shear_stress, obs_normal_stress, obs_ecdisp, obs_shear_strain]\n",
    "            \n",
    "    \n",
    "    return X, Y, t, dt, vl # note we read the first 3 in as out 6 column dataset [X, Y, t]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
