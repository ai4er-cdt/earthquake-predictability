{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bff22d22",
   "metadata": {},
   "source": [
    "# Data Preprocessing Notes for Cascadia\n",
    "Author: Camilla Billari <br> \n",
    "Date: 17/01/24\n",
    "\n",
    "Notes for the data preprocessing that was carried out upon loading Cascadia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d680b4a8-f747-4ebc-9459-1c5f2d1ea356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camillas-MacBook-Pro-2.local\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "\n",
    "import utils.paths as paths\n",
    "from utils.dataset import SlowEarthquakeDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab923818",
   "metadata": {},
   "source": [
    "## Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ccccb",
   "metadata": {},
   "source": [
    "Quickly opened it in Matlab for a sanity check:\n",
    "\n",
    "<img src=\"images/cgb47-notebooks/Datamat.jpg?raw=true\" alt=\"Loaded Data in Matlab Screenshot\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3795856b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['#refs#', 'Area', 'Area_asp', 'Area_belt', 'Lg_term_slip_Rate', 'Nasp', 'Npatches', 'Npatches_asp', 'Npatches_belt', 'Nt_u', 'Nt_v', 'Upotrough_asp', 'Upotroughdot_asp', 'V0pot_asp', 'Vpotrough_asp', 'aa', 'dirs', 'fault_model_IC', 'flag_surrogate', 'id_IN_AspBorder_SSE', 'id_IN_AspBorder_SSE_dilat', 'ind_in', 'ind_in_belt', 'ind_nan', 'km2m', 'll_geom_center_ll', 'mm2m', 'shear_modulus', 'timeline_u', 'timeline_v', 'toc_start', 'upotrough', 'upotrough_asp', 'upotrough_belt', 'upotroughdot', 'upotroughdot_asp', 'upotroughdot_belt', 'urough', 'urough_asp', 'urough_belt', 'urough_mean', 'uroughdot', 'uroughdot_asp', 'uroughdot_belt', 'v0', 'v0_asp', 'v0_belt', 'v0pot', 'v0pot_asp', 'v0pot_belt', 'vpotrough', 'vpotrough_asp', 'vpotrough_belt', 'vrough', 'vrough_asp', 'vrough_belt']\n",
      "Column types: [<HDF5 group \"/#refs#\" (184 members)>, <HDF5 dataset \"Area\": shape (1, 3337), type \"<f8\">, <HDF5 dataset \"Area_asp\": shape (1, 14), type \"|O\">, <HDF5 dataset \"Area_belt\": shape (1, 557), type \"<f8\">, <HDF5 dataset \"Lg_term_slip_Rate\": shape (2, 3339), type \"<f8\">, <HDF5 dataset \"Nasp\": shape (1, 1), type \"<f8\">, <HDF5 dataset \"Npatches\": shape (1, 1), type \"<f8\">, <HDF5 dataset \"Npatches_asp\": shape (14, 1), type \"<f8\">, <HDF5 dataset \"Npatches_belt\": shape (1, 1), type \"<f8\">, <HDF5 dataset \"Nt_u\": shape (1, 1), type \"<f8\">, <HDF5 dataset \"Nt_v\": shape (1, 1), type \"<f8\">, <HDF5 dataset \"Upotrough_asp\": shape (3883, 14), type \"<f8\">, <HDF5 dataset \"Upotroughdot_asp\": shape (3882, 14), type \"<f8\">, <HDF5 dataset \"V0pot_asp\": shape (3882, 14), type \"<f8\">, <HDF5 dataset \"Vpotrough_asp\": shape (3882, 14), type \"<f8\">, <HDF5 dataset \"aa\": shape (1, 1), type \"<f8\">, <HDF5 group \"/dirs\" (5 members)>, <HDF5 dataset \"fault_model_IC\": shape (15, 1), type \"|O\">, <HDF5 dataset \"flag_surrogate\": shape (1, 1), type \"<f8\">, <HDF5 dataset \"id_IN_AspBorder_SSE\": shape (14, 1), type \"|O\">, <HDF5 dataset \"id_IN_AspBorder_SSE_dilat\": shape (14, 1), type \"|O\">, <HDF5 dataset \"ind_in\": shape (1, 14), type \"|O\">, <HDF5 dataset \"ind_in_belt\": shape (1, 3337), type \"|u1\">, <HDF5 dataset \"ind_nan\": shape (1, 3339), type \"|u1\">, <HDF5 dataset \"km2m\": shape (1, 1), type \"<f8\">, <HDF5 dataset \"ll_geom_center_ll\": shape (2, 3337), type \"<f8\">, <HDF5 dataset \"mm2m\": shape (1, 1), type \"<f8\">, <HDF5 dataset \"shear_modulus\": shape (1, 1), type \"<f8\">, <HDF5 dataset \"timeline_u\": shape (3883, 1), type \"<f8\">, <HDF5 dataset \"timeline_v\": shape (3882, 1), type \"<f8\">, <HDF5 dataset \"toc_start\": shape (1, 1), type \"<f8\">, <HDF5 dataset \"upotrough\": shape (3883, 3337), type \"<f8\">, <HDF5 dataset \"upotrough_asp\": shape (1, 14), type \"|O\">, <HDF5 dataset \"upotrough_belt\": shape (3883, 557), type \"<f8\">, <HDF5 dataset \"upotroughdot\": shape (3882, 3337), type \"<f8\">, <HDF5 dataset \"upotroughdot_asp\": shape (1, 14), type \"|O\">, <HDF5 dataset \"upotroughdot_belt\": shape (3882, 557), type \"<f8\">, <HDF5 dataset \"urough\": shape (3883, 3337), type \"<f8\">, <HDF5 dataset \"urough_asp\": shape (1, 14), type \"|O\">, <HDF5 dataset \"urough_belt\": shape (3883, 557), type \"<f8\">, <HDF5 dataset \"urough_mean\": shape (1, 3339), type \"<f8\">, <HDF5 dataset \"uroughdot\": shape (3882, 3337), type \"<f8\">, <HDF5 dataset \"uroughdot_asp\": shape (1, 14), type \"|O\">, <HDF5 dataset \"uroughdot_belt\": shape (3882, 557), type \"<f8\">, <HDF5 dataset \"v0\": shape (1, 3337), type \"<f8\">, <HDF5 dataset \"v0_asp\": shape (1, 14), type \"|O\">, <HDF5 dataset \"v0_belt\": shape (1, 557), type \"<f8\">, <HDF5 dataset \"v0pot\": shape (1, 3337), type \"<f8\">, <HDF5 dataset \"v0pot_asp\": shape (1, 14), type \"|O\">, <HDF5 dataset \"v0pot_belt\": shape (1, 557), type \"<f8\">, <HDF5 dataset \"vpotrough\": shape (3882, 3337), type \"<f8\">, <HDF5 dataset \"vpotrough_asp\": shape (1, 14), type \"|O\">, <HDF5 dataset \"vpotrough_belt\": shape (3882, 557), type \"<f8\">, <HDF5 dataset \"vrough\": shape (3882, 3337), type \"<f8\">, <HDF5 dataset \"vrough_asp\": shape (1, 14), type \"|O\">, <HDF5 dataset \"vrough_belt\": shape (3882, 557), type \"<f8\">]\n",
      "Number of columns: 56\n"
     ]
    }
   ],
   "source": [
    "# Access the .mat file using h5py which reads it in Hierarchical Data Format (version 5) to preserve references\n",
    "data_f = h5py.File(\n",
    "    f\"{paths.MICHEL_SLOW_DATA_DIR}/dynamical_system_variables_rough.mat\", \"r\"\n",
    ")\n",
    "keys = list(data_f.keys())\n",
    "values = list(data_f.values())\n",
    "print(\"Column names:\", keys)\n",
    "print(\"Column types:\", values)\n",
    "print(\"Number of columns:\", len(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85934c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data loader accesses \"upotrough_asp\", which is split into the 14 segments, which are triangulated\n",
    "data_f[\"upotrough_asp\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c1cb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the time array\n",
    "t_data = data_f[\"timeline_u\"]\n",
    "t = t_data[()][\n",
    "    :, 0\n",
    "]  # t_data[()] gets entire dataset; then select rows from the first column\n",
    "dt = t[1] - t[0]  # look at time step in data (1 day)\n",
    "\n",
    "n_samples = t.shape[0]  # n of samples (time)\n",
    "n_segments = data_f[\"upotrough_asp\"].shape[\n",
    "    1\n",
    "]  # diplacement potency of asperity (rough??)\n",
    "\n",
    "print(\"N of t samples: {}, n of segments: {}\".format(n_samples, n_segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e01ce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the triangulated segment 1 and show it in a dataframe\n",
    "disp_potency_asp = data_f[\n",
    "    data_f[\"upotrough_asp\"][0][1]\n",
    "]  # time series of displacement in all 196 triangles in the 1st segment of the asperity\n",
    "\n",
    "df = pd.DataFrame(disp_potency_asp)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f8329d",
   "metadata": {},
   "source": [
    "### Understanding the pre-processing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe58f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding what the data loader is doing...\n",
    "segment = 1\n",
    "x_data = data_f[data_f[\"upotrough_asp\"][0][segment]]\n",
    "upot = dict()\n",
    "\n",
    "upot[\"seg\" + str(segment)] = x_data[()]  # assign it in the empty dictionary\n",
    "print(\"Y:\", upot[\"seg1\"])  # -> this is our Y\n",
    "print(\"Y shape:\", upot[\"seg1\"].shape)  # -> this is our Y\n",
    "\n",
    "print(\n",
    "    \"X:\", np.sum(upot[\"seg\" + str(segment)], axis=1)\n",
    ")  # -> This will be our X for some reason..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc49077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't get the point of this section...\n",
    "Upot_raw = np.empty((n_samples, n_segments))  # empty dict for all segments\n",
    "\n",
    "Upot_raw[:, segment] = np.sum(\n",
    "    upot[\"seg\" + str(segment)], axis=1\n",
    ")  # sum over all segments and assign it to the first...\n",
    "print(\n",
    "    \"Sum at 1: {}\".format(Upot_raw[:, 1])\n",
    ")  # so this literally just has a time series for 1, and has 0 time series for the other segments...\n",
    "print(\"At all other indeces...:\", Upot_raw[:, 2])\n",
    "Upot_raw[:, 2] == Upot_raw[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbf6dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = -Upot_raw[:, segment]  # ???? why are we doing this\n",
    "print(\"X shape:\", X.shape)\n",
    "X = X[..., np.newaxis]\n",
    "print(\"New X shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddde197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y has all the time series for each triangle in segment\n",
    "Y = upot[\"seg\" + str(segment)]\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0110f9ed",
   "metadata": {},
   "source": [
    "## Pre-processed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a81d0",
   "metadata": {},
   "source": [
    "#### Useful info from Michel et al. 2019\n",
    "\n",
    ">\"We use daily sampled position time series in the IGS08 reference frame from the Pacific Geodetic Array (PANGA) and the Plate Boundary Observatory (PBO) maintained by UNAVCO and processed by the Nevada Geodetic Laboratory (http://geodesy.unr.edu, last access August 2017). Most of the available continuous GPS (cGPS) stations were deployed in 2007, and we consider the time range that goes from 2007.0 to 2017.632. We use only time series with at most 40% of missing data and we exclude all the stations in the proximity (< 15 km) of volcanoes to avoid contamination by volcanic signals. We also discard station BLYN because of spurious large displacements of unknown origin that were clearly not observed at nearby stations. The final selection includes NGPS = 352 cGPS stations (Fig. 1a). We then refer all the stations to the North America reference frame using the regional block model of Schmaltze et al. (2014). The position time series are then organized in a M × T matrix Xobs, where M = 3 × NGPS is the total number of time series (East, North, and Vertical direction per each station), and T = 3883 is the total number of observed epochs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97a9f388-7c2f-4869-9e78-035c8daed0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello 29\n",
      "hello\n",
      "{'t0': 2000.0, 'tend': 2030.0, 'Nheaders': None, 'dir_data': 'gtc_quakes_data/slowquakes/', 'case_study': 'Micheletal2019a/dynamical_system_variables_rough', 'data_type': 'nature', 'struct_type': None, 'file_format': 'mat', 'downsample_factor': 1, 'vl': 0.04, 'segment': 1, 'obs_unit': 'm$^3$', 'time_unit': 'yr', 'obs_label': '$P$ [m$^3$]', 'time_label': 'Time [yr]'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg_avg</th>\n",
       "      <th>seg_0</th>\n",
       "      <th>seg_1</th>\n",
       "      <th>seg_2</th>\n",
       "      <th>seg_3</th>\n",
       "      <th>seg_4</th>\n",
       "      <th>seg_5</th>\n",
       "      <th>seg_6</th>\n",
       "      <th>seg_7</th>\n",
       "      <th>seg_8</th>\n",
       "      <th>...</th>\n",
       "      <th>seg_187</th>\n",
       "      <th>seg_188</th>\n",
       "      <th>seg_189</th>\n",
       "      <th>seg_190</th>\n",
       "      <th>seg_191</th>\n",
       "      <th>seg_192</th>\n",
       "      <th>seg_193</th>\n",
       "      <th>seg_194</th>\n",
       "      <th>seg_195</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.510314e+08</td>\n",
       "      <td>87022.678176</td>\n",
       "      <td>-51216.196044</td>\n",
       "      <td>-195371.505863</td>\n",
       "      <td>-252388.298108</td>\n",
       "      <td>372090.056832</td>\n",
       "      <td>290238.755195</td>\n",
       "      <td>271991.646241</td>\n",
       "      <td>218795.685053</td>\n",
       "      <td>87096.609524</td>\n",
       "      <td>...</td>\n",
       "      <td>-714770.112748</td>\n",
       "      <td>-631423.743396</td>\n",
       "      <td>-693599.810348</td>\n",
       "      <td>-7.208255e+05</td>\n",
       "      <td>-739527.228854</td>\n",
       "      <td>-471014.225482</td>\n",
       "      <td>-6.757540e+05</td>\n",
       "      <td>-350155.612260</td>\n",
       "      <td>-517024.526987</td>\n",
       "      <td>2007.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.256806e+08</td>\n",
       "      <td>118857.552212</td>\n",
       "      <td>64765.192887</td>\n",
       "      <td>-66943.170211</td>\n",
       "      <td>-125253.475061</td>\n",
       "      <td>510980.726973</td>\n",
       "      <td>375269.217942</td>\n",
       "      <td>323695.517273</td>\n",
       "      <td>312924.577753</td>\n",
       "      <td>-6911.497818</td>\n",
       "      <td>...</td>\n",
       "      <td>-506075.873333</td>\n",
       "      <td>-448764.275644</td>\n",
       "      <td>-391456.474306</td>\n",
       "      <td>-9.886575e+05</td>\n",
       "      <td>-958004.348328</td>\n",
       "      <td>-740390.446945</td>\n",
       "      <td>-8.927657e+05</td>\n",
       "      <td>-466337.939160</td>\n",
       "      <td>-928475.702850</td>\n",
       "      <td>2007.003438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.074901e+08</td>\n",
       "      <td>-113120.619296</td>\n",
       "      <td>-100329.909243</td>\n",
       "      <td>-117236.092138</td>\n",
       "      <td>-63257.566664</td>\n",
       "      <td>87699.655400</td>\n",
       "      <td>15131.208777</td>\n",
       "      <td>-22576.356489</td>\n",
       "      <td>-13975.055467</td>\n",
       "      <td>-177396.925200</td>\n",
       "      <td>...</td>\n",
       "      <td>-421853.932989</td>\n",
       "      <td>-333693.022748</td>\n",
       "      <td>-204519.903296</td>\n",
       "      <td>-7.137062e+05</td>\n",
       "      <td>-715494.785171</td>\n",
       "      <td>-542145.799983</td>\n",
       "      <td>-6.803446e+05</td>\n",
       "      <td>-366915.287037</td>\n",
       "      <td>-572674.592498</td>\n",
       "      <td>2007.006176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.447256e+08</td>\n",
       "      <td>-51897.143096</td>\n",
       "      <td>-61146.543996</td>\n",
       "      <td>-108560.424295</td>\n",
       "      <td>-80686.019435</td>\n",
       "      <td>178525.612880</td>\n",
       "      <td>98101.791008</td>\n",
       "      <td>48849.079713</td>\n",
       "      <td>53199.150697</td>\n",
       "      <td>-139909.026614</td>\n",
       "      <td>...</td>\n",
       "      <td>-655215.504038</td>\n",
       "      <td>-473799.573780</td>\n",
       "      <td>-345621.989210</td>\n",
       "      <td>-9.187762e+05</td>\n",
       "      <td>-927868.499626</td>\n",
       "      <td>-679886.516377</td>\n",
       "      <td>-8.823582e+05</td>\n",
       "      <td>-474262.121982</td>\n",
       "      <td>-695698.483285</td>\n",
       "      <td>2007.008914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.787377e+08</td>\n",
       "      <td>-60139.943735</td>\n",
       "      <td>-118351.239477</td>\n",
       "      <td>-228181.280629</td>\n",
       "      <td>-226276.200039</td>\n",
       "      <td>270908.204014</td>\n",
       "      <td>154758.192851</td>\n",
       "      <td>92016.023222</td>\n",
       "      <td>86065.362414</td>\n",
       "      <td>-174784.005040</td>\n",
       "      <td>...</td>\n",
       "      <td>-916992.338832</td>\n",
       "      <td>-753637.001609</td>\n",
       "      <td>-546489.401328</td>\n",
       "      <td>-1.036981e+06</td>\n",
       "      <td>-934869.092836</td>\n",
       "      <td>-938970.117667</td>\n",
       "      <td>-1.106399e+06</td>\n",
       "      <td>-800182.900760</td>\n",
       "      <td>-897332.083419</td>\n",
       "      <td>2007.011651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        seg_avg          seg_0          seg_1          seg_2          seg_3  \\\n",
       "0  1.510314e+08   87022.678176  -51216.196044 -195371.505863 -252388.298108   \n",
       "1  1.256806e+08  118857.552212   64765.192887  -66943.170211 -125253.475061   \n",
       "2  1.074901e+08 -113120.619296 -100329.909243 -117236.092138  -63257.566664   \n",
       "3  1.447256e+08  -51897.143096  -61146.543996 -108560.424295  -80686.019435   \n",
       "4  1.787377e+08  -60139.943735 -118351.239477 -228181.280629 -226276.200039   \n",
       "\n",
       "           seg_4          seg_5          seg_6          seg_7          seg_8  \\\n",
       "0  372090.056832  290238.755195  271991.646241  218795.685053   87096.609524   \n",
       "1  510980.726973  375269.217942  323695.517273  312924.577753   -6911.497818   \n",
       "2   87699.655400   15131.208777  -22576.356489  -13975.055467 -177396.925200   \n",
       "3  178525.612880   98101.791008   48849.079713   53199.150697 -139909.026614   \n",
       "4  270908.204014  154758.192851   92016.023222   86065.362414 -174784.005040   \n",
       "\n",
       "   ...        seg_187        seg_188        seg_189       seg_190  \\\n",
       "0  ... -714770.112748 -631423.743396 -693599.810348 -7.208255e+05   \n",
       "1  ... -506075.873333 -448764.275644 -391456.474306 -9.886575e+05   \n",
       "2  ... -421853.932989 -333693.022748 -204519.903296 -7.137062e+05   \n",
       "3  ... -655215.504038 -473799.573780 -345621.989210 -9.187762e+05   \n",
       "4  ... -916992.338832 -753637.001609 -546489.401328 -1.036981e+06   \n",
       "\n",
       "         seg_191        seg_192       seg_193        seg_194        seg_195  \\\n",
       "0 -739527.228854 -471014.225482 -6.757540e+05 -350155.612260 -517024.526987   \n",
       "1 -958004.348328 -740390.446945 -8.927657e+05 -466337.939160 -928475.702850   \n",
       "2 -715494.785171 -542145.799983 -6.803446e+05 -366915.287037 -572674.592498   \n",
       "3 -927868.499626 -679886.516377 -8.823582e+05 -474262.121982 -695698.483285   \n",
       "4 -934869.092836 -938970.117667 -1.106399e+06 -800182.900760 -897332.083419   \n",
       "\n",
       "          time  \n",
       "0  2007.000700  \n",
       "1  2007.003438  \n",
       "2  2007.006176  \n",
       "3  2007.008914  \n",
       "4  2007.011651  \n",
       "\n",
       "[5 rows x 198 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access Cascadia and output dataframe head - need to ask Pritt about his loader\n",
    "dataset = SlowEarthquakeDataset([\"cascadia\"])\n",
    "\n",
    "ds_exp = dataset[\"cascadia\"]\n",
    "X, Y, t = ds_exp[\"X\"], ds_exp[\"Y\"], ds_exp[\"t\"]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    np.hstack((X, Y, t.reshape(-1, 1))),\n",
    "    columns=[ds_exp[\"hdrs\"][\"X\"], *ds_exp[\"hdrs\"][\"Y\"], ds_exp[\"hdrs\"][\"t\"]],\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352e4dda",
   "metadata": {},
   "source": [
    "## Notes on Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d45de35",
   "metadata": {},
   "source": [
    "### General notes:\n",
    "\n",
    "* We have sampled 100% of dataset (in the 3883 day time window).\n",
    "* Downsampling frequency = (Michel et al?)\n",
    "* Original 56 olumns were: ['#refs#', 'Area', 'Area_asp', 'Area_belt', 'Lg_term_slip_Rate', 'Nasp', 'Npatches', 'Npatches_asp', 'Npatches_belt', 'Nt_u', 'Nt_v', 'Upotrough_asp', 'Upotroughdot_asp', 'V0pot_asp', 'Vpotrough_asp', 'aa', 'dirs', 'fault_model_IC', 'flag_surrogate', 'id_IN_AspBorder_SSE', 'id_IN_AspBorder_SSE_dilat', 'ind_in', 'ind_in_belt', 'ind_nan', 'km2m', 'll_geom_center_ll', 'mm2m', 'shear_modulus', 'timeline_u', 'timeline_v', 'toc_start', 'upotrough', 'upotrough_asp', 'upotrough_belt', 'upotroughdot', 'upotroughdot_asp', 'upotroughdot_belt', 'urough', 'urough_asp', 'urough_belt', 'urough_mean', 'uroughdot', 'uroughdot_asp', 'uroughdot_belt', 'v0', 'v0_asp', 'v0_belt', 'v0pot', 'v0pot_asp', 'v0pot_belt', 'vpotrough', 'vpotrough_asp', 'vpotrough_belt', 'vrough', 'vrough_asp', 'vrough_belt'].\n",
    "* Loader output columns: [1, 2, ..., 196], where:\n",
    "    * Each column is a time series for the (rough?) slip displacement potency of each triangle in the chosen segment (1) of the fault asperity.\n",
    "* Pre-processing steps:\n",
    "    * Y is not pre-processed, but X is the negative sum of all Y columns... I am very confused.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79d18dd",
   "metadata": {},
   "source": [
    "### Annotated Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c61e2",
   "metadata": {},
   "source": [
    "#### Setting Experiment Parameter\n",
    "From _params.py_: \n",
    "\n",
    "```python\n",
    "elif exp == \"cascadia\":\n",
    "        parameters = {\n",
    "            \"t0\": 2000.0,           # Starting time window loaded - Note: raw data min = 0\n",
    "            \"tend\": 2030.0,         # Ending time window loaded - Note: raw data max = 5285.9\n",
    "            \"Nheaders\": None,       # Header that np array starts with in import_data\n",
    "            \"dir_data\": \"gtc_quakes_data/slowquakes/\",\n",
    "            \"case_study\": \"Micheletal2019a/dynamical_system_variables_rough\",\n",
    "            \"data_type\": \"nature\",\n",
    "            \"struct_type\": None,\n",
    "            \"file_format\": \"mat\",\n",
    "            \"downsample_factor\": 1, # No downsampling (in != 1, no code has been written for it)\n",
    "            \"vl\": 40e-3,            # Loading velocity\n",
    "            \"segment\": 1,           # Segment in asperity to select\n",
    "            \"obs_unit\": r\"m$^3$\",\n",
    "            \"time_unit\": \"yr\",\n",
    "        }\n",
    "\n",
    "        [...] # Assigns new params for obs and time labels with units\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1026af63",
   "metadata": {},
   "source": [
    "#### Loading and Pre-processing\n",
    "Note: load_data() takes in the parameters defined above, loads and processes the data, and outputs it into X, Y, t, dt, vl.\n",
    "\n",
    "Relevant parts from _load.py_: \n",
    "\n",
    "```python\n",
    "def load_data(exp, dirs, params):\n",
    "\n",
    "    elif params[\"data_type\"] == \"nature\":\n",
    "        [...] # load the file using h5py\n",
    "\n",
    "        # Select the \"upotrough_asp\" and \"timeline_u\" columns in data\n",
    "        # Note \"upotrough_asp\" shape = 14x1, with each cell having shape = n x 3883 (n differs per cell)\n",
    "        # So I would assume all 14 are different time series - are they the neighbouring stations like Adriano was saying?\n",
    "        upotrough_asp_ref = f.get(\"upotrough_asp\") \n",
    "        t_data = f.get(\"timeline_u\")        # shape = 1x3883, observed eppchs\n",
    "        t = t_data[()][:, 0]                # t_data[()] gets entire dataset; then select rows from the first column\n",
    "\n",
    "        dt = t[1] - t[0]                    # look at time step in data (1 day)\n",
    "\n",
    "        n_samples = t.shape[0]              # n of samples\n",
    "        n_segments = upotrough_asp_ref.shape[1] # diplacement potency of asperity (rough??)\n",
    "\n",
    "        upot = dict()                       # diplacement potency dict for desired dict\n",
    "        Upot_raw = np.empty((n_samples, n_segments))    # raw diplacement potency for all segments (though most remain empty?? What is the point of this...)\n",
    "\n",
    "        # Choose desired triangulated segment of the sperity \n",
    "        if params[\"segment\"] is None:\n",
    "            segment = 0\n",
    "        else:\n",
    "            segment = params[\"segment\"]                 # Parameter set at 1 in the loader\n",
    "\n",
    "        x_data = f[upotrough_asp_ref[0][segment]]       # select the time series for the desired segment\n",
    "        upot[\"seg\" + str(segment)] = x_data[()]         # assign it in the empty dictionary\n",
    "        Upot_raw[:, segment] = np.sum(upot[\"seg\" + str(segment)], axis=1) # sum over all triangles... why not average? Why not just access Upotrough_asp instead? - but actually they are different. Questions for Adriano.\n",
    "\n",
    "        Y = upot[\"seg\" + str(segment)]  # output all 196 triangles as Y time series\n",
    "        X = -Upot_raw[:, segment]       # why??? why is our X a sum of all Ys...\n",
    "        X = X[..., np.newaxis]          # reshape from (3883,) to (3883, 1)\n",
    "\n",
    "        vl = params[\"vl\"]\n",
    "        [...] #---- Estimate loading velocity from loading displacenment if not present, but in Cascadia vl=40e-3\n",
    "            \n",
    "    \n",
    "    return X, Y, t, dt, vl # note we read the first 3 in as out 6 column dataset [X, Y, t]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
