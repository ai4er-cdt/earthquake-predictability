{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom loss function using pre-calculated derivatives\n",
    "\n",
    "Notebook to work through developing a custom loss function as in \"JP861 - 003\" but calculating derivatives across whole dataset prior to creating datasets to allow significant smoothing to be performed.\n",
    "\n",
    "This code is largely based on \"AI4ER GTC - Slow Earthquake Time Series Forecasting.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available.\n"
     ]
    }
   ],
   "source": [
    "# Set the system directories\n",
    "import sys\n",
    "import os\n",
    "import socket\n",
    "from utils.paths import MAIN_DIRECTORY\n",
    "\n",
    "if MAIN_DIRECTORY not in sys.path:\n",
    "    sys.path.append(MAIN_DIRECTORY)\n",
    "\n",
    "ROOT_DIRECTORY = \"sys.path.append(os.getcwd() + '/..')\"\n",
    "if ROOT_DIRECTORY not in sys.path:\n",
    "    sys.path.append(ROOT_DIRECTORY)\n",
    "\n",
    "# Import the standard libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "# Import local modules - note: dependent on above path being set correctly\n",
    "from scripts.models.lstm_oneshot_multistep import MultiStepLSTMSingleLayer\n",
    "from scripts.models.tcn_oneshot_multistep import MultiStepTCN\n",
    "from utils.data_preprocessing import (\n",
    "    create_dataset,\n",
    "    moving_average_causal_filter,\n",
    "    split_train_test_forecast_windows,\n",
    "    find_peak_indices,\n",
    "    create_features,\n",
    "    normalise_dataset_multi_feature,\n",
    "    select_features,\n",
    "    calculate_smooth_derivatives\n",
    ")\n",
    "from utils.dataset import SlowEarthquakeDataset\n",
    "from utils.general_functions import set_seed, set_torch_device\n",
    "from utils.nn_train import train_model_multi_feature, eval_model_on_test_set_multi_feature\n",
    "from utils.plotting import plot_random_window, plot_random_test_window\n",
    "\n",
    "# Set a random seed\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "# Set the PyTorch device (GPU/cuda or CPU)\n",
    "device = set_torch_device()\n",
    "\n",
    "# If the notebook is being run on the JASMIN GPU cluster, select the second GPU (index = 1)\n",
    "if socket.gethostname() == \"gpuhost001.jc.rl.ac.uk\":\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.091520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.090652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.089989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.089492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.088243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301716</th>\n",
       "      <td>4.979753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301717</th>\n",
       "      <td>4.979841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301718</th>\n",
       "      <td>4.980150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301719</th>\n",
       "      <td>4.979985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301720</th>\n",
       "      <td>4.980377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301721 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          signal\n",
       "0       5.091520\n",
       "1       5.090652\n",
       "2       5.089989\n",
       "3       5.089492\n",
       "4       5.088243\n",
       "...          ...\n",
       "301716  4.979753\n",
       "301717  4.979841\n",
       "301718  4.980150\n",
       "301719  4.979985\n",
       "301720  4.980377\n",
       "\n",
       "[301721 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = \"p4679\"    # Set this to the name of the experiment you want to train on\n",
    "\n",
    "if exp == \"cascadia\":\n",
    "    column_name = \"seg_avg\"\n",
    "else:\n",
    "    column_name = \"obs_shear_stress\"\n",
    "\n",
    "dataset = SlowEarthquakeDataset(exp)\n",
    "df = pd.DataFrame(\n",
    "    SlowEarthquakeDataset.convert_to_df(dataset, exp)[column_name].rename(\n",
    "        \"signal\"\n",
    "    )\n",
    ")\n",
    "\n",
    "if exp == \"cascadia\":\n",
    "    df = df / 1e8  # Scale the slip potency signal to match magnitude of lab and sim data\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.067449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.987701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.912222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.899803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.897135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23203</th>\n",
       "      <td>4.977414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23204</th>\n",
       "      <td>4.977963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23205</th>\n",
       "      <td>4.978566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23206</th>\n",
       "      <td>4.979127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23207</th>\n",
       "      <td>4.979631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23208 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         signal\n",
       "0      5.067449\n",
       "1      4.987701\n",
       "2      4.912222\n",
       "3      4.899803\n",
       "4      4.897135\n",
       "...         ...\n",
       "23203  4.977414\n",
       "23204  4.977963\n",
       "23205  4.978566\n",
       "23206  4.979127\n",
       "23207  4.979631\n",
       "\n",
       "[23208 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define smoothing window and downsampling factor for each experiment (must be integers)\n",
    "settings = {\n",
    "    \"cascadia\": {\"smoothing_window\": 10, \"downsampling_factor\": 1},\n",
    "    \"p4679\": {\"smoothing_window\": 20, \"downsampling_factor\": 13},\n",
    "    \"p4581\": {\"smoothing_window\": 30, \"downsampling_factor\": 26},\n",
    "    \"b726\": {\"smoothing_window\": 1, \"downsampling_factor\": 1},\n",
    "    \"b698\": {\"smoothing_window\": 2, \"downsampling_factor\": 2},\n",
    "    \"i417\": {\"smoothing_window\": 2, \"downsampling_factor\": 2},\n",
    "    \"sim_b726\": {\"smoothing_window\": 1, \"downsampling_factor\": 1},\n",
    "    \"sim_b698\": {\"smoothing_window\": 2, \"downsampling_factor\": 2},\n",
    "    \"sim_i417\": {\"smoothing_window\": 2, \"downsampling_factor\": 2},\n",
    "}\n",
    "\n",
    "df_filtered = moving_average_causal_filter(df, **settings[exp])\n",
    "\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate smooth second derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define derivative smoothing parameters\n",
    "derivative_smoothing_windows = {\n",
    "    \"cascadia\": 1,\n",
    "    \"p4679\": 1,\n",
    "    \"p4581\": 1,\n",
    "    \"b726\": 1,\n",
    "    \"b698\": 1,\n",
    "    \"i417\": 1,\n",
    "    \"sim_b726\": 1,\n",
    "    \"sim_b698\": 1,\n",
    "    \"sim_i417\": 1,\n",
    "}\n",
    "\n",
    "df_smooth_derivatives  = calculate_smooth_derivatives(df_filtered, **derivative_smoothing_window[exp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineer features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils function create_features() edited to also calculate extra smooth and centred second derivatives to be used for the custom loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.067449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.987701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.912222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.899803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.897135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23203</th>\n",
       "      <td>4.977414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23204</th>\n",
       "      <td>4.977963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23205</th>\n",
       "      <td>4.978566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23206</th>\n",
       "      <td>4.979127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23207</th>\n",
       "      <td>4.979631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23208 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         signal\n",
       "0      5.067449\n",
       "1      4.987701\n",
       "2      4.912222\n",
       "3      4.899803\n",
       "4      4.897135\n",
       "...         ...\n",
       "23203  4.977414\n",
       "23204  4.977963\n",
       "23205  4.978566\n",
       "23206  4.979127\n",
       "23207  4.979631\n",
       "\n",
       "[23208 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features = create_features(df_filtered.copy())\n",
    "feature_list = data.columns\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating smooth derivatives\n",
    "\n",
    "Determining appropriate smoothing windows for calculating smooth derivatives:\n",
    "- Cascadia = None (signal is too noisy for using this approach)\n",
    "- p4679 = 1 (signal is already smooth)\n",
    "- p4581 = 5 (some moderate additional smoothing is useful)\n",
    "- b726 = None (signal is too noisy for using this approach)\n",
    "- b698 = 5 (some moderate additional smoothing is useful)\n",
    "- i417 = 5 (some moderate additional smothing is useful)\n",
    "- sim... = 1 (signals are already smooth)\n",
    "\n",
    "In general, additional smoothing seems to have little impact on the smoothness of the resulting derivatives (particularly the second derivative)\n",
    "\n",
    "p4679 and sims have the smoothest signals and are likely to work the best using this approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "exp = \"p4581\"    # Set this to the name of the experiment you want to train on\n",
    "\n",
    "if exp == \"cascadia\":\n",
    "    column_name = \"seg_avg\"\n",
    "else:\n",
    "    column_name = \"obs_shear_stress\"\n",
    "\n",
    "dataset = SlowEarthquakeDataset(exp)\n",
    "df = pd.DataFrame(\n",
    "    SlowEarthquakeDataset.convert_to_df(dataset, exp)[column_name].rename(\n",
    "        \"signal\"\n",
    "    )\n",
    ")\n",
    "\n",
    "if exp == \"cascadia\":\n",
    "    df = df / 1e8  # Scale the slip potency signal to match magnitude of lab and sim data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-processing\n",
    "settings = {\n",
    "    \"cascadia\": {\"smoothing_window\": 10, \"downsampling_factor\": 1},\n",
    "    \"p4679\": {\"smoothing_window\": 20, \"downsampling_factor\": 13},\n",
    "    \"p4581\": {\"smoothing_window\": 30, \"downsampling_factor\": 26},\n",
    "    \"b726\": {\"smoothing_window\": 1, \"downsampling_factor\": 1},\n",
    "    \"b698\": {\"smoothing_window\": 2, \"downsampling_factor\": 2},\n",
    "    \"i417\": {\"smoothing_window\": 2, \"downsampling_factor\": 2},\n",
    "    \"sim_b726\": {\"smoothing_window\": 1, \"downsampling_factor\": 1},\n",
    "    \"sim_b698\": {\"smoothing_window\": 2, \"downsampling_factor\": 2},\n",
    "    \"sim_i417\": {\"smoothing_window\": 2, \"downsampling_factor\": 2},\n",
    "}\n",
    "\n",
    "df_filtered = moving_average_causal_filter(df, **settings[exp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions\n",
    "derivative_smoothing_windows = {\n",
    "    \"cascadia\": None,\n",
    "    \"p4679\": 1,\n",
    "    \"p4581\": 5,\n",
    "    \"b726\": None,\n",
    "    \"b698\": 5,\n",
    "    \"i417\": 5,\n",
    "    \"sim_b726\": 1,\n",
    "    \"sim_b698\": 1,\n",
    "    \"sim_i417\": 1,\n",
    "}\n",
    "\n",
    "data = df_filtered.copy()\n",
    "derivative_smoothing_window = derivative_smoothing_windows[exp]\n",
    "column_name = \"signal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply extra smoothing\n",
    "data[\"smooth_signal\"] = data.rolling(window = int(derivative_smoothing_window), step = 1, center = True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate derivatives\n",
    "data[\"smooth_first_derivative\"] = np.gradient(data[\"smooth_signal\"])\n",
    "data[\"smooth_second_derivative\"] = np.gradient(data[\"smooth_first_derivative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data and derivatives\n",
    "fig, axs = plt.subplots(\n",
    "    len(data.columns), 1, figsize=(15, 3 * len(data.columns))\n",
    ")\n",
    "\n",
    "for i, column in enumerate(data.columns):\n",
    "    ax = axs[i]\n",
    "    ax.plot(data.index, data[column])\n",
    "    ax.set_ylabel(column)\n",
    "    ax.grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoomed in plots\n",
    "plot_length = 250\n",
    "random_start = random.randint(0, len(data)-plot_length)\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    len(data.columns), 1, figsize=(15, 3 * len(data.columns))\n",
    ")\n",
    "\n",
    "for i, column in enumerate(data.columns):\n",
    "    ax = axs[i]\n",
    "    ax.plot(data.index, data[column])\n",
    "    ax.set_ylabel(column)\n",
    "    ax.grid(False)\n",
    "    ax.set_xlim(random_start, random_start+plot_length)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivative transformation and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "exp = \"p4679\"    # Set this to the name of the experiment you want to train on\n",
    "\n",
    "if exp == \"cascadia\":\n",
    "    column_name = \"seg_avg\"\n",
    "else:\n",
    "    column_name = \"obs_shear_stress\"\n",
    "\n",
    "dataset = SlowEarthquakeDataset(exp)\n",
    "df = pd.DataFrame(\n",
    "    SlowEarthquakeDataset.convert_to_df(dataset, exp)[column_name].rename(\n",
    "        \"signal\"\n",
    "    )\n",
    ")\n",
    "\n",
    "if exp == \"cascadia\":\n",
    "    df = df / 1e8  # Scale the slip potency signal to match magnitude of lab and sim data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-processing\n",
    "settings = {\n",
    "    \"cascadia\": {\"smoothing_window\": 10, \"downsampling_factor\": 1},\n",
    "    \"p4679\": {\"smoothing_window\": 20, \"downsampling_factor\": 13},\n",
    "    \"p4581\": {\"smoothing_window\": 30, \"downsampling_factor\": 26},\n",
    "    \"b726\": {\"smoothing_window\": 1, \"downsampling_factor\": 1},\n",
    "    \"b698\": {\"smoothing_window\": 2, \"downsampling_factor\": 2},\n",
    "    \"i417\": {\"smoothing_window\": 2, \"downsampling_factor\": 2},\n",
    "    \"sim_b726\": {\"smoothing_window\": 1, \"downsampling_factor\": 1},\n",
    "    \"sim_b698\": {\"smoothing_window\": 2, \"downsampling_factor\": 2},\n",
    "    \"sim_i417\": {\"smoothing_window\": 2, \"downsampling_factor\": 2},\n",
    "}\n",
    "\n",
    "df_filtered = moving_average_causal_filter(df, **settings[exp])\n",
    "\n",
    "# Definitions\n",
    "derivative_smoothing_windows = {\n",
    "    \"cascadia\": None,\n",
    "    \"p4679\": 1,\n",
    "    \"p4581\": 5,\n",
    "    \"b726\": None,\n",
    "    \"b698\": 5,\n",
    "    \"i417\": 5,\n",
    "    \"sim_b726\": 1,\n",
    "    \"sim_b698\": 1,\n",
    "    \"sim_i417\": 1,\n",
    "}\n",
    "\n",
    "data = df_filtered.copy()\n",
    "derivative_smoothing_window = derivative_smoothing_windows[exp]\n",
    "column_name = \"signal\"\n",
    "\n",
    "# Apply extra smoothing\n",
    "data[\"smooth_signal\"] = data.rolling(window = int(derivative_smoothing_window), step = 1, center = True).mean()\n",
    "\n",
    "# Calculate derivatives\n",
    "data[\"smooth_first_derivative\"] = np.gradient(data[\"smooth_signal\"])\n",
    "data[\"smooth_second_derivative\"] = np.gradient(data[\"smooth_first_derivative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation and scaling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data and derivatives\n",
    "fig, axs = plt.subplots(\n",
    "    len(data.columns), 1, figsize=(15, 3 * len(data.columns))\n",
    ")\n",
    "\n",
    "for i, column in enumerate(data.columns):\n",
    "    ax = axs[i]\n",
    "    ax.plot(data.index, data[column])\n",
    "    ax.set_ylabel(column)\n",
    "    ax.grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoomed in plots\n",
    "plot_length = 250\n",
    "random_start = random.randint(0, len(data)-plot_length)\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    len(data.columns), 1, figsize=(15, 3 * len(data.columns))\n",
    ")\n",
    "\n",
    "for i, column in enumerate(data.columns):\n",
    "    ax = axs[i]\n",
    "    ax.plot(data.index, data[column])\n",
    "    ax.set_ylabel(column)\n",
    "    ax.grid(False)\n",
    "    ax.set_xlim(random_start, random_start+plot_length)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
